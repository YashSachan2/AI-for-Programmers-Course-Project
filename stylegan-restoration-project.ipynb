{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a7b7e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:29:08.517974Z",
     "iopub.status.busy": "2025-10-12T08:29:08.517363Z",
     "iopub.status.idle": "2025-10-12T08:29:10.058299Z",
     "shell.execute_reply": "2025-10-12T08:29:10.057495Z"
    },
    "papermill": {
     "duration": 1.546833,
     "end_time": "2025-10-12T08:29:10.059884",
     "exception": false,
     "start_time": "2025-10-12T08:29:08.513051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'robust-unsupervised'...\r\n",
      "remote: Enumerating objects: 204, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (10/10), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\r\n",
      "remote: Total 204 (delta 5), reused 5 (delta 5), pack-reused 194 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (204/204), 34.85 MiB | 49.91 MiB/s, done.\r\n",
      "Resolving deltas: 100% (80/80), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/yohan-pg/robust-unsupervised.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c97ee62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:29:10.067480Z",
     "iopub.status.busy": "2025-10-12T08:29:10.067234Z",
     "iopub.status.idle": "2025-10-12T08:29:10.073243Z",
     "shell.execute_reply": "2025-10-12T08:29:10.072561Z"
    },
    "papermill": {
     "duration": 0.011014,
     "end_time": "2025-10-12T08:29:10.074414",
     "exception": false,
     "start_time": "2025-10-12T08:29:10.063400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/robust-unsupervised\n"
     ]
    }
   ],
   "source": [
    "%cd robust-unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8032ed6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:29:10.081320Z",
     "iopub.status.busy": "2025-10-12T08:29:10.081129Z",
     "iopub.status.idle": "2025-10-12T08:30:22.626051Z",
     "shell.execute_reply": "2025-10-12T08:30:22.625064Z"
    },
    "papermill": {
     "duration": 72.550064,
     "end_time": "2025-10-12T08:30:22.627605",
     "exception": false,
     "start_time": "2025-10-12T08:29:10.077541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/jwblangley/pytorch-fid.git\r\n",
      "  Cloning https://github.com/jwblangley/pytorch-fid.git to /tmp/pip-req-build-r_1bzznl\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/jwblangley/pytorch-fid.git /tmp/pip-req-build-r_1bzznl\r\n",
      "  Resolved https://github.com/jwblangley/pytorch-fid.git to commit 3d604a25516746c3a4a5548c8610e99010b2c819\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting tyro\r\n",
      "  Downloading tyro-0.9.33-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro) (0.16)\r\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro) (14.0.0)\r\n",
      "Collecting shtab>=1.5.6 (from tyro)\r\n",
      "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\r\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro) (4.4.4)\r\n",
      "Requirement already satisfied: typing-extensions>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from tyro) (4.14.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pytorch-fid==0.2.1) (1.26.4)\r\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pytorch-fid==0.2.1) (11.2.1)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pytorch-fid==0.2.1) (1.15.3)\r\n",
      "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-fid==0.2.1) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-fid==0.2.1) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro) (2.19.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid==0.2.1) (3.18.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid==0.2.1) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid==0.2.1) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid==0.2.1) (2025.5.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.1->pytorch-fid==0.2.1)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.1->pytorch-fid==0.2.1)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.1->pytorch-fid==0.2.1)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.1->pytorch-fid==0.2.1)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.1->pytorch-fid==0.2.1)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.1->pytorch-fid==0.2.1)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.1->pytorch-fid==0.2.1)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.1->pytorch-fid==0.2.1)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.1->pytorch-fid==0.2.1)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid==0.2.1) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid==0.2.1) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid==0.2.1) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.1->pytorch-fid==0.2.1)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid==0.2.1) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid==0.2.1) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.1->pytorch-fid==0.2.1) (1.3.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-fid==0.2.1) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-fid==0.2.1) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-fid==0.2.1) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-fid==0.2.1) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-fid==0.2.1) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-fid==0.2.1) (2.4.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro) (0.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid==0.2.1) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pytorch-fid==0.2.1) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pytorch-fid==0.2.1) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pytorch-fid==0.2.1) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pytorch-fid==0.2.1) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pytorch-fid==0.2.1) (2024.2.0)\r\n",
      "Downloading tyro-0.9.33-py3-none-any.whl (132 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pytorch-fid\r\n",
      "  Building wheel for pytorch-fid (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for pytorch-fid: filename=pytorch_fid-0.2.1-py3-none-any.whl size=14811 sha256=9e8a41b55435a8011b3a441b73a17f15529ef9a1e1afd7c26109d184e479da1b\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sn_c2thc/wheels/8f/47/c7/95c4bdd845ec42b55ef9e4fe7b594c8304cfa618566f25af22\r\n",
      "Successfully built pytorch-fid\r\n",
      "Installing collected packages: shtab, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, pytorch-fid\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-fid-0.2.1 shtab-1.7.2 tyro-0.9.33\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tyro \"git+https://github.com/jwblangley/pytorch-fid.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd009c0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:30:22.672175Z",
     "iopub.status.busy": "2025-10-12T08:30:22.671828Z",
     "iopub.status.idle": "2025-10-12T08:30:35.365871Z",
     "shell.execute_reply": "2025-10-12T08:30:35.364819Z"
    },
    "papermill": {
     "duration": 12.717744,
     "end_time": "2025-10-12T08:30:35.367451",
     "exception": false,
     "start_time": "2025-10-12T08:30:22.649707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-12 08:30:22--  https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\r\n",
      "Resolving nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)... 18.244.202.81, 18.244.202.50, 18.244.202.77, ...\r\n",
      "Connecting to nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)|18.244.202.81|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 381624121 (364M) [binary/octet-stream]\r\n",
      "Saving to: ‘pretrained_networks/ffhq.pkl’\r\n",
      "\r\n",
      "pretrained_networks 100%[===================>] 363.94M  33.9MB/s    in 12s     \r\n",
      "\r\n",
      "2025-10-12 08:30:35 (31.4 MB/s) - ‘pretrained_networks/ffhq.pkl’ saved [381624121/381624121]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl -O pretrained_networks/ffhq.pkl\n",
    "\n",
    "# This cell replaces the StyleGAN2 download command with one for StyleGAN3.\n",
    "# We are using the 'stylegan3-r' (rotation equivariant) variant trained on FFHQ.\n",
    "# !wget https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhq-1024x1024.pkl -O pretrained_networks/ffhq.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d88423e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:30:35.425780Z",
     "iopub.status.busy": "2025-10-12T08:30:35.424823Z",
     "iopub.status.idle": "2025-10-12T08:30:38.958420Z",
     "shell.execute_reply": "2025-10-12T08:30:38.957604Z"
    },
    "papermill": {
     "duration": 3.568643,
     "end_time": "2025-10-12T08:30:38.960026",
     "exception": false,
     "start_time": "2025-10-12T08:30:35.391383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lpips\r\n",
      "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from lpips) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.11/dist-packages (from lpips) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (1.15.3)\r\n",
      "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (4.67.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->lpips) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->lpips) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->lpips) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->lpips) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->lpips) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->lpips) (2.4.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (2025.5.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.0->lpips) (1.3.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.2.1->lpips) (11.2.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.3->lpips) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.3->lpips) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.3->lpips) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.3->lpips) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.3->lpips) (2024.2.0)\r\n",
      "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lpips\r\n",
      "Successfully installed lpips-0.1.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4f3ff2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:30:39.008191Z",
     "iopub.status.busy": "2025-10-12T08:30:39.007886Z",
     "iopub.status.idle": "2025-10-12T08:30:39.012750Z",
     "shell.execute_reply": "2025-10-12T08:30:39.012081Z"
    },
    "papermill": {
     "duration": 0.030287,
     "end_time": "2025-10-12T08:30:39.013897",
     "exception": false,
     "start_time": "2025-10-12T08:30:38.983610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the original content from run.py\n",
    "with open('/kaggle/working/robust-unsupervised/run.py', 'r') as f:\n",
    "    run_py_content = f.read()\n",
    "\n",
    "# Read the original content from cli.py\n",
    "with open('/kaggle/working/robust-unsupervised/cli.py', 'r') as f:\n",
    "    cli_py_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b73331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:30:39.062530Z",
     "iopub.status.busy": "2025-10-12T08:30:39.062280Z",
     "iopub.status.idle": "2025-10-12T08:30:39.073261Z",
     "shell.execute_reply": "2025-10-12T08:30:39.072584Z"
    },
    "papermill": {
     "duration": 0.036769,
     "end_time": "2025-10-12T08:30:39.074442",
     "exception": false,
     "start_time": "2025-10-12T08:30:39.037673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ run.py updated with early stopping, Adam optimizer, and metrics logging.\n",
      "✅ cli.py updated with 'patience' parameter for early stopping.\n"
     ]
    }
   ],
   "source": [
    "# This cell combines the early stopping logic, the switch to the Adam optimizer,\n",
    "# and the addition of detailed metrics logging into a single, sequential update.\n",
    "\n",
    "import re\n",
    "import math\n",
    "\n",
    "# --- STEP 1: READ THE ORIGINAL, UNMODIFIED FILES ---\n",
    "with open('/kaggle/working/robust-unsupervised/run.py', 'r') as f:\n",
    "    run_py_content = f.read()\n",
    "\n",
    "with open('/kaggle/working/robust-unsupervised/cli.py', 'r') as f:\n",
    "    cli_py_content = f.read()\n",
    "\n",
    "# --- STEP 2: DEFINE THE `project` FUNCTION WITH EARLY STOPPING ---\n",
    "def get_project_with_early_stopping():\n",
    "    return \"\"\"\n",
    "def project(\n",
    "    G,\n",
    "    target: torch.Tensor,\n",
    "    original_image: torch.Tensor,\n",
    "    *,\n",
    "    config: Config,\n",
    "    initial_w=None,\n",
    "    progress=None,\n",
    "):\n",
    "    # Phase I\n",
    "    w = initial_w if initial_w is not None else G.mapping.w_avg.clone()\n",
    "    w.requires_grad_(True)\n",
    "    optimizer = Adam([w], lr=config.lr_phase_1)\n",
    "    \n",
    "    best_loss_1 = math.inf\n",
    "    patience_counter_1 = 0\n",
    "\n",
    "    for step in range(config.n_steps_phase_1):\n",
    "        synth_images = G.synthesis(w, noise_mode=\"const\")\n",
    "        loss, loss_dict = loss_fn(synth_images, target, original_image)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress.update(1, **loss_dict)\n",
    "\n",
    "        if loss.item() < best_loss_1:\n",
    "            best_loss_1 = loss.item()\n",
    "            patience_counter_1 = 0\n",
    "        else:\n",
    "            patience_counter_1 += 1\n",
    "        \n",
    "        if patience_counter_1 >= config.patience:\n",
    "            print(f\"Stopping early in Phase 1 at step {step}.\")\n",
    "            break\n",
    "\n",
    "    # Phase II\n",
    "    w_plus = w.unsqueeze(1).repeat(1, G.num_ws, 1)\n",
    "    w_plus.requires_grad_(True)\n",
    "    optimizer = Adam([w_plus], lr=config.lr_phase_2)\n",
    "\n",
    "    best_loss_2 = math.inf\n",
    "    patience_counter_2 = 0\n",
    "\n",
    "    for step in range(config.n_steps_phase_2):\n",
    "        synth_images = G.synthesis(w_plus, noise_mode=\"const\")\n",
    "        loss, loss_dict = loss_fn(synth_images, target, original_image)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress.update(1, **loss_dict)\n",
    "\n",
    "        if loss.item() < best_loss_2:\n",
    "            best_loss_2 = loss.item()\n",
    "            patience_counter_2 = 0\n",
    "        else:\n",
    "            patience_counter_2 += 1\n",
    "        \n",
    "        if patience_counter_2 >= config.patience:\n",
    "            print(f\"Stopping early in Phase 2 at step {step}.\")\n",
    "            break\n",
    "\n",
    "    # Phase III\n",
    "    w_plus_plus = w_plus.unsqueeze(1).repeat(1, G.num_filters, 1, 1)\n",
    "    w_plus_plus.requires_grad_(True)\n",
    "    optimizer = Adam([w_plus_plus], lr=config.lr_phase_3)\n",
    "    \n",
    "    best_loss_3 = math.inf\n",
    "    patience_counter_3 = 0\n",
    "\n",
    "    for step in range(config.n_steps_phase_3):\n",
    "        synth_images = G.synthesis(w_plus_plus, noise_mode=\"const\")\n",
    "        loss, loss_dict = loss_fn(synth_images, target, original_image)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress.update(1, **loss_dict)\n",
    "        \n",
    "        if loss.item() < best_loss_3:\n",
    "            best_loss_3 = loss.item()\n",
    "            patience_counter_3 = 0\n",
    "        else:\n",
    "            patience_counter_3 += 1\n",
    "        \n",
    "        if patience_counter_3 >= config.patience:\n",
    "            print(f\"Stopping early in Phase 3 at step {step}.\")\n",
    "            break\n",
    "\n",
    "    return synth_images\n",
    "\"\"\"\n",
    "\n",
    "# --- STEP 3: APPLY ALL MODIFICATIONS SEQUENTIALLY TO `run.py` ---\n",
    "\n",
    "# 3.1: Replace the original `project` function with our new version.\n",
    "# This version already includes the Adam optimizer and the correct function signature.\n",
    "project_function_string = get_project_with_early_stopping()\n",
    "updated_run_py_content = re.sub(r\"def project\\\\(.*?\\\\):.*?(?=return synth_images)\", project_function_string.strip(), run_py_content, flags=re.S)\n",
    "\n",
    "# 3.2: Add all necessary imports at the top of the file.\n",
    "imports_to_add = \"\"\"\n",
    "import math\n",
    "from torch.optim import Adam\n",
    "from metrics import calculate_accuracy_lpips, calculate_realism_fid, calculate_fidelity_lpips\n",
    "import shutil\n",
    "\"\"\"\n",
    "updated_run_py_content = re.sub(r'(from robust_unsupervised.prelude import \\*)', r'\\\\1' + imports_to_add, updated_run_py_content)\n",
    "\n",
    "\n",
    "# 3.3: Update the main loop to pass the original image to the project function.\n",
    "updated_run_py_content = updated_run_py_content.replace(\n",
    "    'projected_w = project(G, target=target, progress=progress)',\n",
    "    'projected_w = project(G, target=target, original_image=batch[\"image\"], progress=progress)'\n",
    ")\n",
    "\n",
    "\n",
    "# 3.4: Add the metrics calculation logic to the end of the `run` function.\n",
    "metrics_logging_code = \"\"\"\n",
    "    # --- DETAILED METRICS CALCULATION ---\n",
    "    ground_truth_dir = config.dataset_path\n",
    "    restored_dir = os.path.join(task_dir, os.path.basename(config.dataset_path))\n",
    "    degraded_dir = task_dir\n",
    "    \n",
    "    accuracy = calculate_accuracy_lpips(restored_dir, ground_truth_dir)\n",
    "    realism = calculate_realism_fid(restored_dir, ground_truth_dir)\n",
    "    fidelity = calculate_fidelity_lpips(restored_dir, degraded_dir, degradation.f)\n",
    "\n",
    "    shutil.rmtree(restored_dir)\n",
    "\n",
    "    summary = f\\\"\\\"\\\"\n",
    "    -----------------------------------------------------\n",
    "    PERFORMANCE REPORT FOR TASK: {task_name}\n",
    "    -----------------------------------------------------\n",
    "    - Accuracy (LPIPS ↓): {accuracy:.4f}\n",
    "    - Realism (FID ↓):    {realism:.2f}\n",
    "    - Fidelity (LPIPS ↓): {fidelity:.4f}\n",
    "    -----------------------------------------------------\n",
    "    \\\"\\\"\\\"\n",
    "    print(summary)\n",
    "    with open(os.path.join(task_dir, 'performance_report.txt'), 'w') as f:\n",
    "        f.write(summary)\n",
    "\"\"\"\n",
    "updated_run_py_content = re.sub(r'(if __name__ == \"__main__\":)', metrics_logging_code + r'\\\\n\\\\1', updated_run_py_content, flags=re.S)\n",
    "\n",
    "\n",
    "# --- STEP 4: APPLY MODIFICATIONS TO `cli.py` ---\n",
    "# Add the 'patience' parameter for the early stopping feature.\n",
    "updated_cli_py_content = cli_py_content.replace(\n",
    "    '    n_steps_phase_3: int = 150',\n",
    "    '    n_steps_phase_3: int = 150\\\\n    patience: int = 15  # Steps to wait for improvement before stopping'\n",
    ")\n",
    "\n",
    "\n",
    "# --- STEP 5: WRITE THE FINAL, MODIFIED CONTENT TO THE FILES ---\n",
    "with open('/kaggle/working/robust-unsupervised/run.py', 'w') as f:\n",
    "    f.write(updated_run_py_content)\n",
    "print(\"✅ run.py updated with early stopping, Adam optimizer, and metrics logging.\")\n",
    "\n",
    "with open('/kaggle/working/robust-unsupervised/cli.py', 'w') as f:\n",
    "    f.write(updated_cli_py_content)\n",
    "print(\"✅ cli.py updated with 'patience' parameter for early stopping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f910ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:30:39.121187Z",
     "iopub.status.busy": "2025-10-12T08:30:39.120973Z",
     "iopub.status.idle": "2025-10-12T08:30:45.458632Z",
     "shell.execute_reply": "2025-10-12T08:30:45.457545Z"
    },
    "papermill": {
     "duration": 6.362776,
     "end_time": "2025-10-12T08:30:45.460325",
     "exception": false,
     "start_time": "2025-10-12T08:30:39.097549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepface\r\n",
      "  Downloading deepface-0.0.95-py3-none-any.whl.metadata (35 kB)\r\n",
      "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.32.4)\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.2.3)\r\n",
      "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (5.2.0)\r\n",
      "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.67.1)\r\n",
      "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (11.2.1)\r\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.11.0.86)\r\n",
      "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.18.0)\r\n",
      "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.8.0)\r\n",
      "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.1.1)\r\n",
      "Collecting flask-cors>=4.0.1 (from deepface)\r\n",
      "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Collecting mtcnn>=0.1.0 (from deepface)\r\n",
      "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Collecting retina-face>=0.0.14 (from deepface)\r\n",
      "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting fire>=0.4.0 (from deepface)\r\n",
      "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Collecting gunicorn>=20.1.0 (from deepface)\r\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\r\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.4.0->deepface) (3.1.0)\r\n",
      "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\r\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (8.2.1)\r\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\r\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.6)\r\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.0.2)\r\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (4.13.4)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (3.18.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gunicorn>=20.1.0->deepface) (25.0)\r\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (14.0.0)\r\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.1.0)\r\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (3.14.0)\r\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.16.0)\r\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.4.1)\r\n",
      "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (1.5.1)\r\n",
      "Collecting lz4>=4.3.3 (from mtcnn>=0.1.0->deepface)\r\n",
      "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->deepface) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->deepface) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->deepface) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->deepface) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->deepface) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->deepface) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2025.6.15)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (25.2.10)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (75.2.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (4.14.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.2)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.73.1)\r\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (2.18.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (3.8.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (0.7.2)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.7)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->deepface) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->deepface) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->deepface) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->deepface) (2024.2.0)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (2.19.2)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->deepface) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\r\n",
      "Downloading deepface-0.0.95-py3-none-any.whl (128 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.3/128.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\r\n",
      "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\r\n",
      "Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lz4, gunicorn, fire, mtcnn, flask-cors, retina-face, deepface\r\n",
      "Successfully installed deepface-0.0.95 fire-0.7.1 flask-cors-6.0.1 gunicorn-23.0.0 lz4-4.4.4 mtcnn-1.0.0 retina-face-0.0.17\r\n"
     ]
    }
   ],
   "source": [
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c260ba7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:30:45.570480Z",
     "iopub.status.busy": "2025-10-12T08:30:45.569979Z",
     "iopub.status.idle": "2025-10-12T08:30:45.576994Z",
     "shell.execute_reply": "2025-10-12T08:30:45.576247Z"
    },
    "papermill": {
     "duration": 0.092794,
     "end_time": "2025-10-12T08:30:45.578159",
     "exception": false,
     "start_time": "2025-10-12T08:30:45.485365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ loss_function.py has been updated with the Identity Loss.\n"
     ]
    }
   ],
   "source": [
    "# This code will completely overwrite your loss_function.py file\n",
    "\n",
    "new_loss_function_content = \"\"\"\n",
    "from robust_unsupervised.prelude import *\n",
    "from lpips import LPIPS\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Helper function to preprocess images for the face recognition model\n",
    "def preprocess_for_face_recognition(tensor_image):\n",
    "    # The model expects images in a specific format (BGR, specific size etc.)\n",
    "    # We convert our PyTorch tensor to a NumPy array that deepface can use.\n",
    "    # The tensor is expected to be in range [-1, 1], so we shift to [0, 255]\n",
    "    image_np = (tensor_image.permute(0, 2, 3, 1) * 127.5 + 127.5).clamp(0, 255).to(torch.uint8).cpu().numpy()\n",
    "    # DeepFace handles the rest of the preprocessing internally\n",
    "    return image_np\n",
    "\n",
    "class IDLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IDLoss, self).__init__()\n",
    "        # Load the ArcFace model. It will be downloaded automatically the first time.\n",
    "        # We only need the model for embedding extraction.\n",
    "        self.model = DeepFace.build_model('ArcFace')\n",
    "        self.model.eval()\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # x and y are the generated and ground-truth images, respectively.\n",
    "        # Both are PyTorch tensors.\n",
    "        \n",
    "        # Preprocess images for the model\n",
    "        x_np = preprocess_for_face_recognition(x)\n",
    "        y_np = preprocess_for_face_recognition(y)\n",
    "\n",
    "        # Get the embeddings. DeepFace expects a list of images.\n",
    "        x_embedding = DeepFace.represent(img_path=x_np[0], model=self.model, enforce_detection=False)\n",
    "        y_embedding = DeepFace.represent(img_path=y_np[0], model=self.model, enforce_detection=False)\n",
    "        \n",
    "        # Convert embeddings back to PyTorch tensors\n",
    "        x_embedding_tensor = torch.tensor(x_embedding[0]['embedding']).unsqueeze(0).to(x.device)\n",
    "        y_embedding_tensor = torch.tensor(y_embedding[0]['embedding']).unsqueeze(0).to(y.device)\n",
    "\n",
    "        # Calculate Cosine Similarity Loss\n",
    "        loss = 1 - torch.cosine_similarity(x_embedding_tensor, y_embedding_tensor)\n",
    "        return loss.mean()\n",
    "\n",
    "class LossFunction(nn.Module):\n",
    "    def __init__(self, lambda_l1: float = 0.1, lambda_id: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.lambda_l1 = lambda_l1\n",
    "        self.lambda_id = lambda_id\n",
    "        self.l1 = nn.L1Loss()\n",
    "        self.lpips = LPIPS(net=\"vgg\").cuda()\n",
    "        self.id_loss = IDLoss().cuda()\n",
    "\n",
    "    def forward(self, synth_images, target_images, original_images):\n",
    "        # The main forward pass now accepts the original image\n",
    "        \n",
    "        # L1 Loss (Pixel-wise)\n",
    "        l1_loss = self.l1(synth_images, target_images)\n",
    "\n",
    "        # LPIPS Loss (Perceptual)\n",
    "        lpips_loss = self.lpips(synth_images, target_images).mean()\n",
    "        \n",
    "        # Identity Loss\n",
    "        id_loss = self.id_loss(synth_images, original_images)\n",
    "\n",
    "        # Combine the losses\n",
    "        total_loss = lpips_loss + self.lambda_l1 * l1_loss + self.lambda_id * id_loss\n",
    "        \n",
    "        return total_loss, {\n",
    "            \"loss\": total_loss.item(),\n",
    "            \"lpips\": lpips_loss.item(),\n",
    "            \"l1\": l1_loss.item(),\n",
    "            \"id\": id_loss.item(),\n",
    "        }\n",
    "\n",
    "# Global instance\n",
    "loss_fn = LossFunction()\n",
    "\"\"\"\n",
    "\n",
    "# Write the new content to the file\n",
    "with open('/kaggle/working/robust-unsupervised/loss_function.py', 'w') as f:\n",
    "    f.write(new_loss_function_content)\n",
    "\n",
    "print(\"✅ loss_function.py has been updated with the Identity Loss.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfe962eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:30:45.631067Z",
     "iopub.status.busy": "2025-10-12T08:30:45.630406Z",
     "iopub.status.idle": "2025-10-12T08:30:45.637269Z",
     "shell.execute_reply": "2025-10-12T08:30:45.636575Z"
    },
    "papermill": {
     "duration": 0.035331,
     "end_time": "2025-10-12T08:30:45.638472",
     "exception": false,
     "start_time": "2025-10-12T08:30:45.603141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ metrics.py created successfully with functions for Accuracy, Realism, and Fidelity.\n"
     ]
    }
   ],
   "source": [
    "# This cell creates a new file, 'metrics.py', to handle performance evaluation.\n",
    "# We will calculate Accuracy (LPIPS), Realism (FID), and Fidelity (LPIPS on re-degraded images).\n",
    "\n",
    "metrics_py_content = \"\"\"\n",
    "from robust_unsupervised.prelude import *\n",
    "from pytorch_fid.fid_score import calculate_fid_given_paths\n",
    "from lpips import LPIPS\n",
    "import os\n",
    "\n",
    "# Initialize the LPIPS model once to be reused.\n",
    "lpips_fn = LPIPS(net=\"vgg\").cuda()\n",
    "\n",
    "def calculate_accuracy_lpips(restored_dir: str, ground_truth_dir: str) -> float:\n",
    "    \\\"\\\"\\\"\n",
    "    Calculates Accuracy, defined as the average LPIPS between restored\n",
    "    images and their ground truth counterparts. \n",
    "    \\\"\\\"\\\"\n",
    "    print(\"Calculating Accuracy (LPIPS)...\")\n",
    "    restored_files = sorted([os.path.join(restored_dir, f) for f in os.listdir(restored_dir)])\n",
    "    gt_files = sorted([os.path.join(ground_truth_dir, f) for f in os.listdir(ground_truth_dir)])\n",
    "    \n",
    "    total_lpips = 0.0\n",
    "    num_images = len(restored_files)\n",
    "    \n",
    "    for restored_path, gt_path in zip(restored_files, gt_files):\n",
    "        restored_img = read_image_tensor(restored_path).cuda()\n",
    "        gt_img = read_image_tensor(gt_path).cuda()\n",
    "        lpips_score = lpips_fn(restored_img, gt_img).item()\n",
    "        total_lpips += lpips_score\n",
    "        \n",
    "    return total_lpips / num_images if num_images > 0 else 0.0\n",
    "\n",
    "def calculate_realism_fid(restored_dir: str, ground_truth_dir: str) -> float:\n",
    "    \\\"\\\"\\\"\n",
    "    Calculates Realism using Frechet Inception Distance (FID) between the set of \n",
    "    restored images and the set of ground truth images. [cite: 226]\n",
    "    The paper uses a patch-based FID (pFID), but we use standard FID as a strong proxy.\n",
    "    \\\"\\\"\\\"\n",
    "    print(\"Calculating Realism (FID)...\")\n",
    "    # These parameters are commonly used for FID calculation.\n",
    "    dims = 2048\n",
    "    batch_size = 32\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    fid_value = calculate_fid_given_paths(\n",
    "        paths=[restored_dir, ground_truth_dir],\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        dims=dims\n",
    "    )\n",
    "    return fid_value\n",
    "    \n",
    "def calculate_fidelity_lpips(restored_dir: str, degraded_dir: str, degradation_fn) -> float:\n",
    "    \\\"\\\"\\\"\n",
    "    Calculates Fidelity, defined as the average LPIPS between a re-degraded\n",
    "    restored image and the original degraded target image. [cite: 228]\n",
    "    \\\"\\\"\\\"\n",
    "    print(\"Calculating Fidelity (LPIPS)...\")\n",
    "    restored_files = sorted([os.path.join(restored_dir, f) for f in os.listdir(restored_dir)])\n",
    "    degraded_files = sorted([os.path.join(degraded_dir, f) for f in os.listdir(degraded_dir)])\n",
    "\n",
    "    total_lpips = 0.0\n",
    "    num_images = len(restored_files)\n",
    "\n",
    "    for restored_path, degraded_path in zip(restored_files, degraded_files):\n",
    "        restored_img = read_image_tensor(restored_path).cuda()\n",
    "        degraded_target_img = read_image_tensor(degraded_path).cuda()\n",
    "        \n",
    "        # Apply the same degradation to our restored image. [cite: 229]\n",
    "        re_degraded_img = degradation_fn(restored_img)\n",
    "        \n",
    "        lpips_score = lpips_fn(re_degraded_img, degraded_target_img).item()\n",
    "        total_lpips += lpips_score\n",
    "\n",
    "    return total_lpips / num_images if num_images > 0 else 0.0\n",
    "\n",
    "def read_image_tensor(path: str) -> torch.Tensor:\n",
    "    \\\"\\\"\\\"Helper to read an image and convert it to a PyTorch tensor in [-1, 1] range.\\\"\\\"\\\"\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    img_tensor = F.to_tensor(img) * 2 - 1\n",
    "    return img_tensor.unsqueeze(0)\n",
    "\"\"\"\n",
    "\n",
    "# Write the new content to the file\n",
    "with open('/kaggle/working/robust-unsupervised/metrics.py', 'w') as f:\n",
    "    f.write(metrics_py_content)\n",
    "\n",
    "print(\"✅ metrics.py created successfully with functions for Accuracy, Realism, and Fidelity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e7ddb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T08:30:45.691293Z",
     "iopub.status.busy": "2025-10-12T08:30:45.690796Z",
     "iopub.status.idle": "2025-10-12T11:23:13.669009Z",
     "shell.execute_reply": "2025-10-12T11:23:13.668088Z"
    },
    "papermill": {
     "duration": 10348.005987,
     "end_time": "2025-10-12T11:23:13.670886",
     "exception": false,
     "start_time": "2025-10-12T08:30:45.664899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/robust-unsupervised\n",
      "restored_samples\r\n",
      "Loading generator from pretrained_networks/ffhq.pkl...\r\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\r\n",
      "100%|█████████████████████████████████████████| 528M/528M [00:02<00:00, 217MB/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/upsampling/XL/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/upsampling/XL/datasets/samples\r\n",
      "- 0000\r\n",
      "W:   0%|                                                | 0/150 [00:00<?, ?it/s]Setting up PyTorch plugin \"bias_act_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \r\n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\r\n",
      "  warnings.warn(\r\n",
      "Done.\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:41<00:00,  3.59it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:18<00:00,  8.32it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:20<00:00,  7.27it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:18<00:00,  8.30it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:18<00:00,  8.31it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:20<00:00,  7.26it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/denoising/XL/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/denoising/XL/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.20it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.29it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.20it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/deartifacting/XL/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/deartifacting/XL/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:17<00:00,  1.94it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:17<00:00,  1.94it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.87it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:17<00:00,  1.94it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:17<00:00,  1.94it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:19<00:00,  1.88it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/inpainting/XL/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/inpainting/XL/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.20it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.20it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/upsampling/L/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/upsampling/L/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:18<00:00,  8.04it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:18<00:00,  8.04it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:21<00:00,  7.06it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:18<00:00,  8.05it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:18<00:00,  8.04it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:21<00:00,  7.05it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/denoising/L/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/denoising/L/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.20it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.20it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/deartifacting/L/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/deartifacting/L/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:17<00:00,  1.94it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:17<00:00,  1.94it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.87it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:17<00:00,  1.94it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:17<00:00,  1.94it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:19<00:00,  1.88it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/inpainting/L/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/inpainting/L/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.20it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.20it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/upsampling/M/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/upsampling/M/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:19<00:00,  7.52it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:19<00:00,  7.56it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:22<00:00,  6.69it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:19<00:00,  7.54it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:19<00:00,  7.55it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:22<00:00,  6.68it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/denoising/M/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/denoising/M/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.19it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.19it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/deartifacting/M/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/deartifacting/M/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:17<00:00,  1.93it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:17<00:00,  1.93it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.87it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:17<00:00,  1.93it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:17<00:00,  1.94it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.87it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/inpainting/M/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/inpainting/M/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.19it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.19it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/upsampling/S/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/upsampling/S/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:22<00:00,  6.58it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:22<00:00,  6.65it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:25<00:00,  5.96it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:22<00:00,  6.64it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:22<00:00,  6.61it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:25<00:00,  5.93it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/denoising/S/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/denoising/S/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.19it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.19it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/deartifacting/S/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/deartifacting/S/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:17<00:00,  1.93it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:17<00:00,  1.93it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.87it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:17<00:00,  1.93it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:17<00:00,  1.93it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.87it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/inpainting/S/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/inpainting/S/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.20it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.20it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/upsampling/XS/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/upsampling/XS/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:31<00:00,  4.76it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:31<00:00,  4.78it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:34<00:00,  4.41it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:31<00:00,  4.78it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:31<00:00,  4.78it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:33<00:00,  4.41it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/denoising/XS/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/denoising/XS/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.19it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.19it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/deartifacting/XS/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/deartifacting/XS/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:17<00:00,  1.93it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:17<00:00,  1.93it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.87it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:17<00:00,  1.94it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:17<00:00,  1.93it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.87it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/single_tasks/inpainting/XS/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/single_tasks/inpainting/XS/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.29it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.20it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:05<00:00,  2.28it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.20it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/composed_tasks/UN/2/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/composed_tasks/UN/2/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:20<00:00,  7.49it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:19<00:00,  7.50it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:22<00:00,  6.65it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:19<00:00,  7.50it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:19<00:00,  7.50it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:22<00:00,  6.64it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/composed_tasks/UA/2/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/composed_tasks/UA/2/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:22<00:00,  6.77it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:22<00:00,  6.74it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:24<00:00,  6.05it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:22<00:00,  6.77it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:22<00:00,  6.77it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:24<00:00,  6.05it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/composed_tasks/UP/2/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/composed_tasks/UP/2/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:20<00:00,  7.49it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:20<00:00,  7.46it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:22<00:00,  6.65it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:19<00:00,  7.50it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:19<00:00,  7.52it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:22<00:00,  6.65it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/composed_tasks/NA/2/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/composed_tasks/NA/2/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:18<00:00,  1.92it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:17<00:00,  1.92it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.86it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:18<00:00,  1.92it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:18<00:00,  1.92it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.86it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/composed_tasks/NP/2/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/composed_tasks/NP/2/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:06<00:00,  2.27it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:06<00:00,  2.27it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:08<00:00,  2.18it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:06<00:00,  2.26it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:06<00:00,  2.26it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:09<00:00,  2.17it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/composed_tasks/AP/2/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/composed_tasks/AP/2/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:18<00:00,  1.92it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:18<00:00,  1.92it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.85it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:18<00:00,  1.92it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:18<00:00,  1.92it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.86it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/composed_tasks/UNA/3/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/composed_tasks/UNA/3/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:22<00:00,  6.62it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:22<00:00,  6.61it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:24<00:00,  6.00it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:22<00:00,  6.77it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:22<00:00,  6.75it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:24<00:00,  6.03it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/composed_tasks/UNP/3/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/composed_tasks/UNP/3/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:19<00:00,  7.51it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:19<00:00,  7.52it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:22<00:00,  6.64it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:20<00:00,  7.48it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:19<00:00,  7.51it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:22<00:00,  6.63it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/composed_tasks/UAP/3/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/composed_tasks/UAP/3/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:22<00:00,  6.74it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:22<00:00,  6.76it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:24<00:00,  6.02it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:22<00:00,  6.75it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:22<00:00,  6.75it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:24<00:00,  6.05it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/composed_tasks/NAP/3/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/composed_tasks/NAP/3/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:18<00:00,  1.92it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:18<00:00,  1.92it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.86it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [01:18<00:00,  1.92it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [01:18<00:00,  1.92it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [01:20<00:00,  1.86it/s]\r\n",
      "out/restored_samples/2025-10-12T083055/composed_tasks/UNAP/4/\r\n",
      "/kaggle/working/robust-unsupervised/out/restored_samples/2025-10-12T083055/composed_tasks/UNAP/4/datasets/samples\r\n",
      "- 0000\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:22<00:00,  6.56it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:22<00:00,  6.54it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:26<00:00,  5.75it/s]\r\n",
      "- 0001\r\n",
      "W: 100%|██████████████████████████████████████| 150/150 [00:23<00:00,  6.36it/s]\r\n",
      "W+: 100%|█████████████████████████████████████| 150/150 [00:23<00:00,  6.39it/s]\r\n",
      "W++: 100%|████████████████████████████████████| 150/150 [00:26<00:00,  5.72it/s]\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/robust-unsupervised\n",
    "\n",
    "!python run.py --dataset_path datasets/samples"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10451.319294,
   "end_time": "2025-10-12T11:23:15.580360",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-12T08:29:04.261066",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
